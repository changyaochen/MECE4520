# Data Science for Mechanical Systems
_Last update: 2021-10-23_.

This repo contains the materials for the course "MECE 4520: Data Science for Mechanical Systems", offered by the Department of Mechanical Engineering at Columbia University, during the Fall 2021 term. [Link](http://www.columbia.edu/cu/bulletin/uwb/#/cu/bulletin/uwb/subj/MECE/E4520-20213-001/) on Directory of Classes.

## Objective
This course aims to provide the students a general introduction of data science and machine learning, with hands-on exercises and applications in mechanical system. The main topics to cover includes supervised learning problems, such as linear regressions and classifications; unsupervised learning problems such as clustering; and reinforcement learning problems. At the end of the course, the students should be equipped with basic concepts data science, and comfortable of applying them to practical problems.

## Time and location
* Lectures: Tuesday 1:10 PM ~ 3:40 PM.
* Location: Rennert Hall at Kraft Center.
* Office Hours: Thursday via Zoom

## Staffs
* Lecturer: Changyao Chen (cc2759@columbia.edu)
* TA: Xin Meng (xm2216@columbia.edu)

## Prerequisites
Linear algebra. Knowledge of basic computer programming (_e.g._, Python, Matlab, R, Java).

## Course format and grading policy
The course will delivered as a series of 2.5-hour long lectures. The grading will be 60% homework, and 40% final project. There will be in total 4 homework (HW) assignments, which are due throughout the course. The final project will be a group-based, 5-minute presentation of a selected topic (details TBD).

## Syllabus
|  **Date**  | **Subject**                                                                                                | **Optional Readings**   | **Due that day**               |
| :--------: | :--------------------------------------------------------------------------------------------------------- | :---------------------- | :----------------------------- |
| 2021-09-14 | Lecture 1: Introduction and linear algebra.                                                                | DDSE 1.1, 1.2           |                                |
| 2021-09-21 | Lecture 2: Statistic primer.                                                                               | ISE 2.1                 |
| 2021-09-28 | Lecture 3: Linear regression.                                                                              | ISE 3.1, 3.2            |                                |
| 2021-10-05 | Lecture 4: Classification.                                                                                 | DDSE 4.1, ISE 4.1 - 4.3 | HW #1                          |
| 2021-10-12 | Lecture 5: Gradient descent.                                                                               |                         |                                |
| 2021-10-19 | Lecture 6: (Mid-term week) Regularization. Feature selection. Dimension reduction. Final project workshop. |                         | HW #2                          |
| 2021-10-26 | Lecture 7: Tree-based models.                                                                              | ISL 8.1, 8.2            |
| 2021-11-02 | No class (Election Day, University Holiday).                                                               |                         |                                |
| 2021-11-09 | Lecture 8: Neural Networks.                                                                                |                         | HW #3, Final project selection |
| 2021-11-16 | Lecture 9: Unsupervised learning and reinforcement learning.                                               |
| 2021-11-23 | Lecture 10: (Thanksgiving week) Dynamical system. Course summary.                                          |                         |                                |
| 2021-11-30 | Final project presentations, part I.                                                                       |                         |                                |
| 2021-12-07 | Final project presentations, part II.                                                                      |                         | HW #4                          |

\* DDSE is short for Data-Driven Science and Engineering

\* ISL is short for An Introduction to Statistical Learning

## Topics to cover
In this course, we encourage the participants to get hands-on experience as much as possible. Therefore, we will prepare Jupyter Notebooks that correspond to each lecture's content, and recommend the students to make the most of them.

**Introduction and linear algebra**: General course structure. Introduction to Python (with lab session using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb)). Linear algebra review: vector, matrix properties and operations, eigenvalue and eigenvector, Single Value Decomposition).

**Statistic primer**: Probability review. Descriptive statistics. Central limit theorem. Point estimation and confidence interval. Hypothesis test concept, and two sample hypothesis test.

**Linear regression**: Simple linear regression. Residual analysis. Identification and handling of multi-collinearity. Multi-variable linear regression. Normal equation.

**Classification**: Logistic regression. Maximum likelihood estimation.

**Gradient descent**: Gradient descent: batch, stochastic, mini-batch.

**Regularization. Feature selection. Dimension reduction**: Overfitting, cross-validation and bootstrap. Best subset, forward, backward selection. L1 (Lasso) and L2 (Ridge) regularization. Revisit of SVD. Principle Component Analysis.

**Tree-based models**: Single decision tree with recursive binary splitting approach. Bagging, Random Forest and Boosting.

**Neural Networks**: Feed-forward Neural Networks (NN). Back propagation. Introduction of Convolutional NN and Recurrent NN.

**Unsupervised learning and reinforcement learning**: Clustering methods (k-means, kd-tree, spectral clustering). Multi-arm bandit. Greedy, epsilon-greedy, and upper confidence bound policies.

**Dynamical system**: Fourier transform. Linear control theory, and data-driven dynamical system.

## Reference
### Text book:
* Data-Driven Science and Engineering ([link](http://www.databookuw.com/))
### Data science
* An Introduction to Statistical Learning, First edition ([link](https://www.statlearning.com/), [pdf](https://static1.squarespace.com/static/5ff2adbe3fe4fe33db902812/t/6009dd9fa7bc363aa822d2c7/1611259312432/ISLR+Seventh+Printing.pdf))
* The Elements of
Statistical Learning ([link](https://web.stanford.edu/~hastie/ElemStatLearn/))
* Python for Data Analysis ([link](https://www.oreilly.com/library/view/python-for-data/9781449323592/))
* Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow ([link](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/))
### Python and general programming
* Python Crash Course ([link](https://nostarch.com/pythoncrashcourse2e))
* Real Python ([link](https://realpython.com/))
* The Linux Command Line ([link](https://linuxcommand.org/tlcl.php))


