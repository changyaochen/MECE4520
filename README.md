# Data Science for Mechanical Systems
_Last update: 2025-08-29_.

This repo contains the materials for the course "MECE 4520: Data Science for Mechanical Systems", offered by the Department of Mechanical Engineering at Columbia University, during the Fall 2025 term. [Link](https://doc.sis.columbia.edu/#subj/MECE/E4520-20253-001/) on Directory of Classes.

Past course evaluations (5-point scale): 4.6 (2023), 4.5 (2022), 4.2 (2021).

## Objective
This course aims to give the students a general introduction to data science and machine learning, with hands-on exercises and applications in mechanical systems. The main topics to cover include supervised learning problems, such as linear regressions and classifications; unsupervised learning problems such as clustering; and reinforcement learning problems. At the end of the course, the students should be equipped with basic concepts of data science, and comfortable applying them to practical problems.

## Time and location
* Lectures: Tuesday and Thursday, 10:10 AM - 11:25 AM.
* Location: 501 Schermerhorn Hall.
* Office Hours: TBD.

## Staffs
* Lecturer: Changyao Chen (cc2759).
* TA: TBD.

## Course format and grading policy
The course will delivered as a series of lectures. The grading will be **60%** homework and **40%** final project. There will be in total **about 7** homework (HW) assignments, which are due throughout the course. The final project will be a group-based, 5-minute presentation of a selected topic.

## Preliminary Syllabus
| **Week** | **Subject**                                   | **Optional Readings** | **Due that week**       |
|--------: | :-------------------------------------------- | :-------------------- | :---------------------- |
|        1 | Introduction and linear algebra primer        | ISL 2.1               |                         |
|        2 | Statistic primer                              |                       | HW #0                   |
|        3 | Linear regression                             | ISL 3.1, 3.2          |                         |
|        4 | Linear regression                             |                       | HW #1                   |
|        5 | Classification. Gradient descent              | ISL 4.3               |                         |
|        6 | Regularization. Feature selection             | ISL 6.1, 6.2          | HW #2                   |
|        7 | Dimension reduction. Final project workshop   |                       |                         |
|        8 | Tree-based models                             | ISL 8.1, 8.2          |                         |
|        9 | Neural Networks                               |                       | HW #3                   |
|       10 | Unsupervised learning                         | ISL 12.2              | Final project selection |
|       11 | Reinforcement learning                        |                       | HW #4                   |
|       12 | Course summary                                |                       |                         |
|       13 | Final project presentations, part I           |                       | HW #5                   |
|       14 | Final project presentations, part II          |                       |                         |

\* The homework is due at Monday 11:59 PM of the given week

\* ISL is short for An Introduction to Statistical Learning with application in Python ([link](https://www.statlearning.com/))

## Topics to cover
In this course, we encourage the students to get hands-on experience as much as possible.
Therefore, we will prepare Jupyter Notebooks that correspond to each lecture's content,
and recommend the students to make the most of them.

**Introduction and linear algebra**:
General course structure. Introduction to Python (with lab session using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb)).
Linear algebra review: vector, matrix properties and operations, eigenvalue and eigenvector.
Single Value Decomposition (SVD).

**Statistic primer**:
Probability review. Descriptive statistics. Central limit theorem.
Point estimation and confidence interval.
Hypothesis test concept, and two sample hypothesis test.

**Linear regression**:
Simple linear regression. Residual analysis. Identification and handling of multicollinearity.
Multi-variable linear regression. Normal equation.

**Classification**:
Logistic regression. Maximum likelihood estimation.

**Gradient descent**: Batch, stochastic, mini-batch gradient descent.

**Regularization. Feature selection. Dimension reduction**:
Overfitting, cross-validation, and bootstrap.
Best subset, forward, backward selection.
L1 (Lasso) and L2 (Ridge) regularization.
Revisit of SVD.
Principle Component Analysis (PCA).

**Tree-based models**:
Single decision tree with recursive binary splitting approach.
Bagging, Random Forest, and Boosting.

**Neural Networks**:
Feed-forward Neural Networks (NN). Back-propagation.
Introduction of Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), and Transformer.

**Unsupervised learning**:
Clustering methods (k-means, kd-tree, spectral clustering).

**Reinforcement learning**:
Multi-arm bandit. Greedy, epsilon-greedy, and upper confidence bound policies.
Q-learning.


## Reference
While the course will follow the syllabus and the materials provided,
the following references are recommended for further reading.

### Data science
* An Introduction to Statistical Learning with Application in Python ([link](https://www.statlearning.com/))
* Data-Driven Science and Engineering, 2nd edition ([link](http://www.databookuw.com/))
* The Elements of
Statistical Learning ([link](https://web.stanford.edu/~hastie/ElemStatLearn/))
* Python for Data Analysis ([link](https://www.oreilly.com/library/view/python-for-data/9781449323592/))
* Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow ([link](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/))

### Python and general programming
* Python Crash Course ([link](https://nostarch.com/pythoncrashcourse2e))
* Real Python ([link](https://realpython.com/))
* The Linux Command Line ([link](https://linuxcommand.org/tlcl.php))


