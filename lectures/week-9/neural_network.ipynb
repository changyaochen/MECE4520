{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b208db55-e5d8-4410-b29a-ae8bc497c500",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "A neural network (NN) is a computational model inspired by the structure and function of the human brain. It consists of interconnected nodes or \"neurons\" organized in layers: input, hidden, and output. Each neuron processes information based on its inputs and weights, passing the result to the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89936266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:30:34.883988Z",
     "start_time": "2021-11-08T05:30:34.261448Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cb5e42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:30:35.604692Z",
     "start_time": "2021-11-08T05:30:35.324320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_extreme</th>\n",
       "      <th>perimeter_extreme</th>\n",
       "      <th>area_extreme</th>\n",
       "      <th>smoothness_extreme</th>\n",
       "      <th>compactness_extreme</th>\n",
       "      <th>concavity_extreme</th>\n",
       "      <th>concave_extreme</th>\n",
       "      <th>symmetry_extreme</th>\n",
       "      <th>fractal_extreme</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave_mean  ...  \\\n",
       "0          0.11840           0.27760          0.3001       0.14710  ...   \n",
       "1          0.08474           0.07864          0.0869       0.07017  ...   \n",
       "2          0.10960           0.15990          0.1974       0.12790  ...   \n",
       "3          0.14250           0.28390          0.2414       0.10520  ...   \n",
       "4          0.10030           0.13280          0.1980       0.10430  ...   \n",
       "\n",
       "   texture_extreme  perimeter_extreme  area_extreme  smoothness_extreme  \\\n",
       "0            17.33             184.60        2019.0              0.1622   \n",
       "1            23.41             158.80        1956.0              0.1238   \n",
       "2            25.53             152.50        1709.0              0.1444   \n",
       "3            26.50              98.87         567.7              0.2098   \n",
       "4            16.67             152.20        1575.0              0.1374   \n",
       "\n",
       "   compactness_extreme  concavity_extreme  concave_extreme  symmetry_extreme  \\\n",
       "0               0.6656             0.7119           0.2654            0.4601   \n",
       "1               0.1866             0.2416           0.1860            0.2750   \n",
       "2               0.4245             0.4504           0.2430            0.3613   \n",
       "3               0.8663             0.6869           0.2575            0.6638   \n",
       "4               0.2050             0.4000           0.1625            0.2364   \n",
       "\n",
       "   fractal_extreme  label  \n",
       "0          0.11890      1  \n",
       "1          0.08902      1  \n",
       "2          0.08758      1  \n",
       "3          0.17300      1  \n",
       "4          0.07678      1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/changyaochen/MECE4520/master/\"\n",
    "    \"data/breast_cancer.csv\")\n",
    "data[\"label\"] = data[\"diagnosis\"].apply(lambda x: 0 if x == \"B\" else 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66a9935",
   "metadata": {},
   "source": [
    "## Construction of a 2-layer NN\n",
    "\n",
    "In this example, we will demonstrate a simple 2-layer NN, with the breast cancer dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83b3bc42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:30:36.461187Z",
     "start_time": "2021-11-08T05:30:36.452582Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"radius_mean\",\n",
    "    \"texture_mean\",\n",
    "    \"perimeter_mean\",\n",
    "    \"area_mean\",\n",
    "    \"smoothness_mean\",\n",
    "    \"compactness_mean\",\n",
    "    \"concavity_mean\",\n",
    "    \"concave_mean\",\n",
    "    \"symmetry_mean\",\n",
    "    \"fractal_mean\",\n",
    "]\n",
    "label = \"label\"\n",
    "\n",
    "# train test split\n",
    "X_raw, X_raw_test, Y, Y_test = train_test_split(\n",
    "    data[features].values, data[label].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize the input\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_raw)\n",
    "X = scaler.transform(X_raw)\n",
    "X_test = scaler.transform(X_raw_test)\n",
    "\n",
    "# formatting\n",
    "Y = Y.reshape((-1, 1))\n",
    "Y_test = Y_test.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d533c7-c70c-4803-834d-065c0d1862e3",
   "metadata": {},
   "source": [
    "## Forward propagation\n",
    "\n",
    "Forward propagation in a NN refers to the process of passing input data through the network to generate an output.\n",
    "\n",
    "Here we will demonstrate forward propgation in our example NN, using the matrix representation, and the notation introduced in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e91b03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:30:38.324219Z",
     "start_time": "2021-11-08T05:30:38.312448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of W_1 is (3, 10)\n",
      "Shape of b_1 is (3, 1)\n",
      "Shape of W_2 is (1, 3)\n",
      "Shape of b_1 is (1, 1)\n",
      "\n",
      "Shape of Z_1 is (455, 3)\n",
      "Samples for Z_1:\n",
      "[[ 0.16410112 -4.76306361  3.93309998]\n",
      " [-0.46604358  4.1992739   9.5658238 ]\n",
      " [-1.60754809 -0.23753874 -1.01727238]\n",
      " [ 1.37695245  2.28649564 -5.09016965]\n",
      " [ 0.12721277  3.49293739  0.32441791]]\n",
      "Shape of A_1 is (455, 3)\n",
      "Samples for A_1:\n",
      "[[0.47421887 0.00490603 0.98314001]\n",
      " [0.32445766 0.97466643 0.99993863]\n",
      " [0.13297977 0.31284592 0.29223288]\n",
      " [0.75206111 0.85032936 0.00698167]\n",
      " [0.46503108 0.94996148 0.61233221]]\n",
      "\n",
      "Shape of Z_2 is (455, 1)\n",
      "Samples for Z_2:\n",
      "[[ 0.16410112 -4.76306361  3.93309998]\n",
      " [-0.46604358  4.1992739   9.5658238 ]\n",
      " [-1.60754809 -0.23753874 -1.01727238]\n",
      " [ 1.37695245  2.28649564 -5.09016965]\n",
      " [ 0.12721277  3.49293739  0.32441791]]\n",
      "Shape of A_2 is (455, 1)\n",
      "Samples for A_2:\n",
      "[[0.59207723]\n",
      " [0.84761911]\n",
      " [0.69066552]\n",
      " [0.76062638]\n",
      " [0.82363926]]\n"
     ]
    }
   ],
   "source": [
    "# forward pass for a simple 2-layer NN, with 3 hidden units\n",
    "np.random.seed(10)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Calculates sigmoid function.\"\"\"\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "# parameters for the first layer\n",
    "W_1 = np.random.normal(size=(3, X.shape[1]))\n",
    "print(f\"Shape of W_1 is {W_1.shape}\")\n",
    "\n",
    "b_1 = np.random.normal(size=(3, 1))\n",
    "print(f\"Shape of b_1 is {b_1.shape}\")\n",
    "\n",
    "# parameters for the second layer\n",
    "W_2 = np.random.normal(size=(1, 3))\n",
    "print(f\"Shape of W_2 is {W_2.shape}\")\n",
    "\n",
    "b_2 = np.random.normal(size=(1, 1))\n",
    "print(f\"Shape of b_1 is {b_2.shape}\")\n",
    "\n",
    "# calculate the forward propagation\n",
    "Z_1 = X @ W_1.T\n",
    "print(f\"\\nShape of Z_1 is {Z_1.shape}\")\n",
    "print(\"Samples for Z_1:\")\n",
    "print(Z_1[:5])\n",
    "\n",
    "A_1 = sigmoid(Z_1 + b_1.T) \n",
    "print(f\"Shape of A_1 is {A_1.shape}\")\n",
    "print(\"Samples for A_1:\")\n",
    "print(A_1[:5])\n",
    "\n",
    "Z_2 = A_1 @ W_2.T\n",
    "print(f\"\\nShape of Z_2 is {Z_2.shape}\")\n",
    "print(\"Samples for Z_2:\")\n",
    "print(Z_1[:5])\n",
    "\n",
    "A_2 = Y_hat = sigmoid(Z_2 + b_2.T)\n",
    "print(f\"Shape of A_2 is {A_2.shape}\")\n",
    "print(\"Samples for A_2:\")\n",
    "print(A_2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b7fd37",
   "metadata": {},
   "source": [
    "## Training a NN with backward propagation\n",
    "\n",
    "Backward propagation, commonly known as backpropagation, is a fundamental process in training neural networks. It refers to the method of adjusting the weights and biases of a neural network by propagating the error backward from the output layer to the input layer. \n",
    "\n",
    "Here we will demonstrate the backward propagation using the matrix notation, on the example NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f5c368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:30:39.199951Z",
     "start_time": "2021-11-08T05:30:39.194453Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward_prop(\n",
    "    X: np.array,\n",
    "    W_1: np.array,\n",
    "    b_1: np.array,\n",
    "    W_2: np.array,\n",
    "    b_2: np.array,\n",
    ") -> Tuple:\n",
    "    \"\"\"Performs the forward propagation of the given NN.\"\"\"\n",
    "    # Note the NN structure is passed in from outside.\n",
    "    Z_1 = X @ W_1.T\n",
    "    A_1 = sigmoid(Z_1 + b_1.T)\n",
    "    \n",
    "    Z_2 = A_1 @ W_2.T\n",
    "    A_2 = Y = sigmoid(Z_2 + b_2.T)\n",
    "    \n",
    "    return A_2, Z_2, A_1, Z_1\n",
    "\n",
    "Y_hat, _, _, _ = forward_prop(X=X, W_1=W_1, b_1=b_1, W_2=W_2, b_2=b_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37acb87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:30:39.531194Z",
     "start_time": "2021-11-08T05:30:39.522853Z"
    }
   },
   "outputs": [],
   "source": [
    "def derivatives_by_backprop(\n",
    "    X: np.array,\n",
    "    Y: np.array,\n",
    "    W_1: np.array,\n",
    "    b_1: np.array,\n",
    "    W_2: np.array,\n",
    "    b_2: np.array,\n",
    ") -> Tuple:\n",
    "    \"\"\"Calculates the derivatives of the parameters by backforward propagation.\n",
    "    \n",
    "    Here we assume it is a binary classification problem, with sigmoid activation functions.\n",
    "    \"\"\"\n",
    "    # forward propagation\n",
    "    dW_2, db_2, dW_1, db_1 = 0, 0, 0, 0\n",
    "    Y_hat, Z_2, A_1, Z_1 = forward_prop(X=X, W_1=W_1, b_1=b_1, W_2=W_2, b_2=b_2)\n",
    "    n = len(Y_hat)\n",
    "    \n",
    "    loss = -np.mean(np.multiply(Y, np.log(Y_hat)) + np.multiply(1 - Y, np.log(1 - Y_hat)))\n",
    "    \n",
    "    dZ_2 = Y_hat - Y\n",
    "    dW_2 = dZ_2.T @ A_1 / n\n",
    "    db_2 = np.mean(dZ_2.T, axis=1, keepdims=True) \n",
    "    \n",
    "    dZ_1 = np.multiply(dZ_2 @ W_2, np.multiply(A_1, 1 - A_1))\n",
    "    dW_1 = (dZ_1.T @ X) / n\n",
    "    db_1 = np.mean(dZ_1.T, axis=1, keepdims=True) \n",
    "    \n",
    "    return dW_2, db_2, dW_1, db_1, loss\n",
    "\n",
    "dW_2, db_2, dW_1, db_1, loss = derivatives_by_backprop(X=X, Y=Y, W_1=W_1, b_1=b_1, W_2=W_2, b_2=b_2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2de336b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:30:39.907568Z",
     "start_time": "2021-11-08T05:30:39.898704Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "    X: np.array,\n",
    "    Y: np.array,\n",
    "    W_1_init: np.array,\n",
    "    b_1_init: np.array,\n",
    "    W_2_init: np.array,\n",
    "    b_2_init: np.array,\n",
    "    learning_rate: float = 0.01,\n",
    "    epsilon: float = 1e-6,\n",
    "    verbose: bool = False,\n",
    ") -> Tuple:\n",
    "    \"\"\"Runs gradient descent to fit the NN via backprop.\"\"\"\n",
    "    W_1 = W_1_init\n",
    "    b_1 = b_1_init\n",
    "    W_2 = W_2_init\n",
    "    b_2 = b_2_init\n",
    "    losses = [float(\"inf\"), ]\n",
    "    roc_auc_scores = [0.5, ]\n",
    "    \n",
    "    diff_in_loss = float(\"inf\")\n",
    "    iteration = 0\n",
    "    while abs(diff_in_loss) > epsilon:\n",
    "        iteration += 1\n",
    "        dW_2, db_2, dW_1, db_1, loss = derivatives_by_backprop(\n",
    "            X=X, Y=Y, W_1=W_1, b_1=b_1, W_2=W_2, b_2=b_2\n",
    "        ) \n",
    "        \n",
    "        W_1 -= learning_rate * dW_1\n",
    "        b_1 -= learning_rate * db_1\n",
    "        W_2 -= learning_rate * dW_2\n",
    "        b_2 -= learning_rate * db_2\n",
    "        \n",
    "        losses.append(loss)\n",
    "        diff_in_loss = losses[-1] - losses[-2]\n",
    "        \n",
    "        Y_hat, _, _, _ = forward_prop(X=X, W_1=W_1, b_1=b_1, W_2=W_2, b_2=b_2)\n",
    "        roc_auc = roc_auc_score(y_true=Y, y_score=Y_hat)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "        if verbose and iteration % 10 == 0:\n",
    "            print(loss, roc_auc)\n",
    "    return W_1, b_1, W_2, b_2, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893b0001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:38:08.847636Z",
     "start_time": "2021-11-08T05:38:08.605916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833557062365721 0.1278603053750983\n",
      "0.6919297915722733 0.40731162328795467\n",
      "0.6221831830749797 0.7705341995282824\n",
      "0.5667720895357119 0.8880498200024827\n",
      "0.5215585720622693 0.9298423470021102\n",
      "0.4839962605525145 0.9451111019158357\n",
      "0.4523753008520904 0.9553523399677246\n",
      "0.42546955449198726 0.9608557123350022\n",
      "0.4023620540738291 0.9643729052013075\n",
      "0.3823494894203707 0.9665039102908926\n",
      "0.3648838371694929 0.9681383705052344\n",
      "0.34953341792280357 0.9694211114329457\n",
      "0.3359553890933618 0.9708693673190715\n",
      "0.32387555184301897 0.9714279803037199\n",
      "0.3130730233613099 0.9721107295071791\n"
     ]
    }
   ],
   "source": [
    "# parameters for the first layer\n",
    "np.random.seed(42)\n",
    "W_1_init = np.random.normal(size=(3, X.shape[1]))\n",
    "b_1_init = np.random.normal(size=(3, 1))\n",
    "\n",
    "# parameters for the second layer\n",
    "W_2_init = np.random.normal(size=(1, 3))\n",
    "b_2_init = np.random.normal(size=(1, 1))\n",
    "\n",
    "W_1, b_1, W_2, b_2, losses = gradient_descent(\n",
    "    X=X,\n",
    "    Y=Y,\n",
    "    W_1_init=W_1_init,\n",
    "    b_1_init=b_1_init,\n",
    "    W_2_init=W_2_init,\n",
    "    b_2_init=b_2_init,\n",
    "    learning_rate=0.1,\n",
    "    epsilon=1e-3,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5760f7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:36:40.907264Z",
     "start_time": "2021-11-08T05:36:40.899968Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9905011464133638"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "Y_test_hat, _, _, _ = forward_prop(X=X_test, W_1=W_1, b_1=b_1, W_2=W_2, b_2=b_2)\n",
    "roc_auc_score(y_true=Y_test, y_score=Y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9ad370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:37:49.042801Z",
     "start_time": "2021-11-08T05:37:48.108037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7402 - auc: 0.8234 - val_loss: 0.7267 - val_auc: 0.9053\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7251 - auc: 0.8552 - val_loss: 0.7133 - val_auc: 0.9351\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7119 - auc: 0.8794 - val_loss: 0.7015 - val_auc: 0.9487\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.7001 - auc: 0.9010 - val_loss: 0.6910 - val_auc: 0.9564\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 999us/step - loss: 0.6897 - auc: 0.9199 - val_loss: 0.6821 - val_auc: 0.9669\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6809 - auc: 0.9325 - val_loss: 0.6737 - val_auc: 0.9738\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6726 - auc: 0.9416 - val_loss: 0.6662 - val_auc: 0.9766\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6652 - auc: 0.9504 - val_loss: 0.6597 - val_auc: 0.9789\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6586 - auc: 0.9568 - val_loss: 0.6541 - val_auc: 0.9802\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.6528 - auc: 0.9615 - val_loss: 0.6488 - val_auc: 0.9805\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6473 - auc: 0.9630 - val_loss: 0.6432 - val_auc: 0.9835\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6416 - auc: 0.9674 - val_loss: 0.6381 - val_auc: 0.9820\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6363 - auc: 0.9683 - val_loss: 0.6331 - val_auc: 0.9830\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6312 - auc: 0.9720 - val_loss: 0.6282 - val_auc: 0.9823\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6261 - auc: 0.9719 - val_loss: 0.6232 - val_auc: 0.9841\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6209 - auc: 0.9740 - val_loss: 0.6182 - val_auc: 0.9840\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 1ms/step - loss: 0.6157 - auc: 0.9742 - val_loss: 0.6131 - val_auc: 0.9831\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 992us/step - loss: 0.6103 - auc: 0.9747 - val_loss: 0.6078 - val_auc: 0.9843\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 995us/step - loss: 0.6049 - auc: 0.9755 - val_loss: 0.6023 - val_auc: 0.9849\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 987us/step - loss: 0.5992 - auc: 0.9755 - val_loss: 0.5964 - val_auc: 0.9840\n"
     ]
    }
   ],
   "source": [
    "# train a NN with Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def keras_model(nn_size: int, num_features: int, num_layers: int):\n",
    "    \"\"\"Creates a simple Keras model.\"\"\"\n",
    "    inputs = keras.Input(\n",
    "        shape=(num_features, ), name=\"inputs\")\n",
    "    x = inputs\n",
    "    for i in range(num_layers):\n",
    "        x = layers.Dense(\n",
    "            nn_size, activation=\"sigmoid\", name=f\"desnse_layer_{i}\")(x)\n",
    "\n",
    "    outputs = layers.Dense(\n",
    "        1, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"simple_model\")\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"AUC\"])\n",
    "    return model\n",
    "\n",
    "model = keras_model(nn_size=3, num_features=X.shape[1], num_layers=1)\n",
    "history = model.fit(\n",
    "    x=X,\n",
    "    y=Y,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2de337c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T05:37:51.398657Z",
     "start_time": "2021-11-08T05:37:51.329772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 528us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9842777595807403"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "roc_auc_score(y_true=Y_test, y_score=model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
