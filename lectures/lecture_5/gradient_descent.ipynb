{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bca68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\", {'grid.linestyle':'--'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = pd.read_csv(\"../lecture_3/auto_mpg.csv\")\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb5358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_loss(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    betas: np.ndarray,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the loss of a linear regression problem.\"\"\"\n",
    "    if not isinstance(betas, np.ndarray):\n",
    "        betas = np.array(betas)\n",
    "\n",
    "    loss = np.sum(np.square(y - X @ betas))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73cb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_auto = np.vstack((np.ones(shape=len(auto)), auto[\"weight\"].values.T)).T\n",
    "y_auto = auto[\"mpg\"].values\n",
    "\n",
    "# test run\n",
    "betas = [70, -0.01]\n",
    "auto_loss(X=X_auto, y=y_auto, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix beta_1 at -0.01\n",
    "losses = []\n",
    "beta_0s = np.linspace(start=35, stop=75, num=100)\n",
    "for b in beta_0s:\n",
    "    betas = [b, -0.01]\n",
    "    loss = auto_loss(X=X_auto, y=y_auto, betas=betas)\n",
    "    losses.append(loss)\n",
    "    \n",
    "# plot the loss function\n",
    "sns.lineplot(x=beta_0s, y=losses)\n",
    "plt.xlabel(\"intercept\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2260414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_loss_gradient(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    betas: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Calculates the gradient of the loss of a linear regression problem.\"\"\"\n",
    "    if not isinstance(betas, np.ndarray):\n",
    "        betas = np.array(betas)\n",
    "    \n",
    "    grad_0 = -2 * np.sum(y - X @ betas)\n",
    "    grad_1 = -2 * np.sum(np.dot((y - X @ betas), X[:, 1]))\n",
    "    \n",
    "    return np.array([grad_0, grad_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40fde4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent with just the intercept\n",
    "lr = 0.0001  # learning rate\n",
    "slope = -0.01  # the fixed slope, i.e., beta_1\n",
    "\n",
    "# initial guesses\n",
    "b0_current = 70  \n",
    "difference = float(\"inf\")\n",
    "\n",
    "# start iterative udpate\n",
    "threshold = 1e-1\n",
    "beta_0s_iter = [b0_current]\n",
    "losses_iter = []\n",
    "while abs(difference) > threshold:\n",
    "    loss_current = auto_loss(X=X_auto, y=y_auto, betas=[b0_current, slope])\n",
    "    losses_iter.append(loss_current)\n",
    "    \n",
    "    b0_next = b0_current - lr * auto_loss_gradient(X=X_auto, \n",
    "                                                   y=y_auto, \n",
    "                                                   betas=[b0_current, slope])[0]  # only take the first element\n",
    "    loss_next = auto_loss(X=X_auto, y=y_auto, betas=[b0_next, slope])\n",
    "    b0_current = b0_next\n",
    "    beta_0s_iter.append(b0_current)\n",
    "    \n",
    "    difference = loss_next - loss_current\n",
    "    \n",
    "# plot the loss function\n",
    "sns.lineplot(x=beta_0s, y=losses)\n",
    "# plot the iterative updates\n",
    "sns.scatterplot(x=beta_0s_iter[:-1], y=losses_iter, color=\"red\", alpha=0.3)\n",
    "plt.xlabel(\"intercept\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full gradient descent\n",
    "beta_1s = np.linspace(start=-0.01, stop=-0.006, num=100)\n",
    "X, Y = np.meshgrid(beta_0s, beta_1s)\n",
    "losses_2d = np.zeros(shape=X.shape)  # initialize the losses\n",
    "for i, x in enumerate(X):\n",
    "    for j in range(len(x)):\n",
    "        losses_2d[i][j] = auto_loss(X=X_auto, y=y_auto, betas=[X[i][j], Y[i][j]])\n",
    "        \n",
    "# make the 3d plot\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "# plot the actual minimum\n",
    "betas_min = [46.317, -0.008]\n",
    "ax.scatter(\n",
    "    xs=[betas_min[0],], \n",
    "    ys=[betas_min[1],], \n",
    "    zs=[auto_loss(X=X_auto, y=y_auto, betas=betas_min)],\n",
    "    s=100,\n",
    "    color=\"black\",\n",
    ")\n",
    "# plot the loss function\n",
    "surf = ax.plot_surface(X, Y, losses_2d, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False, alpha=0.2)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a120e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_loss_gradient(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    betas: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Calculates the gradient of the loss of a linear regression problem.\"\"\"\n",
    "    if not isinstance(betas, np.ndarray):\n",
    "        betas = np.array(betas)\n",
    "    \n",
    "    grad_0 = -2 * np.sum(y - X @ betas)\n",
    "    grad_1 = -2 * np.sum(np.dot((y - X @ betas), X[:, 1]))\n",
    "    \n",
    "    return np.array([grad_0, grad_1])\n",
    "\n",
    "# gradient descent with both intercept and slope\n",
    "lr = 1e-5  # learning rate\n",
    "\n",
    "# initial guesses\n",
    "b_current = np.array([70, -0.007])  \n",
    "difference = float(\"inf\")\n",
    "\n",
    "# start iterative udpate\n",
    "threshold = 1e-1\n",
    "betas_iter = [b_current]\n",
    "losses_iter = []\n",
    "while abs(difference) > threshold:\n",
    "    loss_current = auto_loss(X=X_auto, y=y_auto, betas=b_current)\n",
    "    print(b_current, loss_current)\n",
    "    losses_iter.append(loss_current)\n",
    "    \n",
    "    b_next = b_current - lr * auto_loss_gradient(X=X_auto, \n",
    "                                                 y=y_auto, \n",
    "                                                 betas=b_current) \n",
    "    b_next[1] = -0.007\n",
    "    loss_next = auto_loss(X=X_auto, y=y_auto, betas=b_next)\n",
    "    b_current = b_next\n",
    "    betas_iter.append(b_current)\n",
    "    \n",
    "    difference = loss_next - loss_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752bbee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
